'tok_embeddings.weight',
'layers.0.attention.wq_a.weight',
'layers.0.attention.q_norm.weight',
'layers.0.attention.wq_b.weight',
'layers.0.attention.wkv_a.weight',
'layers.0.attention.kv_norm.weight',
'layers.0.attention.wkv_b.weight',
'layers.0.attention.wo.weight',
'layers.0.attention_norm.weight',  // input_layernorm
'layers.0.ffn_norm.weight',  //  post_attention_layernorm
'layers.0.feed_forward.w1.weight',
'layers.0.feed_forward.w2.weight',
'layers.0.feed_forward.w3.weight',
'layers.1.attention.wq_a.weight',
'layers.1.attention.q_norm.weight',
'layers.1.attention.wq_b.weight',
'layers.1.attention.wkv_a.weight',
'layers.1.attention.kv_norm.weight',
'layers.1.attention.wkv_b.weight',
'layers.1.attention.wo.weight',
'layers.1.attention_norm.weight',
'layers.1.ffn_norm.weight',
'layers.1.feed_forward.w1.weight',
'layers.1.feed_forward.w2.weight',
'layers.1.feed_forward.w3.weight',
'layers.2.attention.wq_a.weight',
'layers.2.attention.q_norm.weight',
'layers.2.attention.wq_b.weight',
'layers.2.attention.wkv_a.weight',
'layers.2.attention.kv_norm.weight',
'layers.2.attention.wkv_b.weight',
'layers.2.attention.wo.weight',
'layers.2.attention_norm.weight',
'layers.2.ffn_norm.weight',
'layers.2.feed_forward.w1.weight',
'layers.2.feed_forward.w2.weight',
'layers.2.feed_forward.w3.weight',
'layers.3.attention.wq_a.weight',
'layers.3.attention.q_norm.weight',
'layers.3.attention.wq_b.weight',
'layers.3.attention.wkv_a.weight',
'layers.3.attention.kv_norm.weight',
'layers.3.attention.wkv_b.weight',
'layers.3.attention.wo.weight',
'layers.3.attention_norm.weight',
'layers.3.ffn_norm.weight',
'layers.3.moe.expert_bias',
'layers.3.moe.tokens_per_expert',
'layers.3.moe.experts.w1',
'layers.3.moe.experts.w2',
'layers.3.moe.experts.w3',
'layers.3.moe.router.gate.weight',
'layers.3.moe.shared_expert.w1',
'layers.3.moe.shared_expert.w2',
'layers.3.moe.shared_expert.w3',
'layers.4.attention.wq_a.weight',
'layers.4.attention.q_norm.weight',
'layers.4.attention.wq_b.weight',
'layers.4.attention.wkv_a.weight',
'layers.4.attention.kv_norm.weight',
'layers.4.attention.wkv_b.weight',
'layers.4.attention.wo.weight',
'layers.4.attention_norm.weight',
'layers.4.ffn_norm.weight',
'layers.4.moe.expert_bias',
'layers.4.moe.tokens_per_expert',
'layers.4.moe.experts.w1',
'layers.4.moe.experts.w2',
'layers.4.moe.experts.w3',
'layers.4.moe.router.gate.weight',
'layers.4.moe.shared_expert.w1',
'layers.4.moe.shared_expert.w2',
'layers.4.moe.shared_expert.w3',
'layers.5.attention.wq_a.weight',
'layers.5.attention.q_norm.weight',
'layers.5.attention.wq_b.weight',
'layers.5.attention.wkv_a.weight',
'layers.5.attention.kv_norm.weight',
'layers.5.attention.wkv_b.weight',
'layers.5.attention.wo.weight',
'layers.5.attention_norm.weight',
'layers.5.ffn_norm.weight',
'layers.5.moe.expert_bias',
'layers.5.moe.tokens_per_expert',
'layers.5.moe.experts.w1',
'layers.5.moe.experts.w2',
'layers.5.moe.experts.w3',
'layers.5.moe.router.gate.weight',
'layers.5.moe.shared_expert.w1',
'layers.5.moe.shared_expert.w2',
'layers.5.moe.shared_expert.w3',
'layers.6.attention.wq_a.weight',
'layers.6.attention.q_norm.weight',
'layers.6.attention.wq_b.weight',
'layers.6.attention.wkv_a.weight',
'layers.6.attention.kv_norm.weight',
'layers.6.attention.wkv_b.weight',
'layers.6.attention.wo.weight',
'layers.6.attention_norm.weight',
'layers.6.ffn_norm.weight',
'layers.6.moe.expert_bias',
'layers.6.moe.tokens_per_expert',
'layers.6.moe.experts.w1',
'layers.6.moe.experts.w2',
'layers.6.moe.experts.w3',
'layers.6.moe.router.gate.weight',
'layers.6.moe.shared_expert.w1',
'layers.6.moe.shared_expert.w2',
'layers.6.moe.shared_expert.w3',
'layers.7.attention.wq_a.weight',
'layers.7.attention.q_norm.weight',
'layers.7.attention.wq_b.weight',
'layers.7.attention.wkv_a.weight',
'layers.7.attention.kv_norm.weight',
'layers.7.attention.wkv_b.weight',
'layers.7.attention.wo.weight',
'layers.7.attention_norm.weight',
'layers.7.ffn_norm.weight',
'layers.7.moe.expert_bias',
'layers.7.moe.tokens_per_expert',
'layers.7.moe.experts.w1',
'layers.7.moe.experts.w2',
'layers.7.moe.experts.w3',
'layers.7.moe.router.gate.weight',
'layers.7.moe.shared_expert.w1',
'layers.7.moe.shared_expert.w2',
'layers.7.moe.shared_expert.w3',
'layers.8.attention.wq_a.weight',
'layers.8.attention.q_norm.weight',
'layers.8.attention.wq_b.weight',
'layers.8.attention.wkv_a.weight',
'layers.8.attention.kv_norm.weight',
'layers.8.attention.wkv_b.weight',
'layers.8.attention.wo.weight',
'layers.8.attention_norm.weight',
'layers.8.ffn_norm.weight',
'layers.8.moe.expert_bias',
'layers.8.moe.tokens_per_expert',
'layers.8.moe.experts.w1',
'layers.8.moe.experts.w2',
'layers.8.moe.experts.w3',
'layers.8.moe.router.gate.weight',
'layers.8.moe.shared_expert.w1',
'layers.8.moe.shared_expert.w2',
'layers.8.moe.shared_expert.w3',
'layers.9.attention.wq_a.weight',
'layers.9.attention.q_norm.weight',
'layers.9.attention.wq_b.weight',
'layers.9.attention.wkv_a.weight',
'layers.9.attention.kv_norm.weight',
'layers.9.attention.wkv_b.weight',
'layers.9.attention.wo.weight',
'layers.9.attention_norm.weight',
'layers.9.ffn_norm.weight',
'layers.9.moe.expert_bias',
'layers.9.moe.tokens_per_expert',
'layers.9.moe.experts.w1',
'layers.9.moe.experts.w2',
'layers.9.moe.experts.w3',
'layers.9.moe.router.gate.weight',
'layers.9.moe.shared_expert.w1',
'layers.9.moe.shared_expert.w2',
'layers.9.moe.shared_expert.w3',
'norm.weight',
'output.weight'
